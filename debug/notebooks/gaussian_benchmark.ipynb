{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# [`ProxNest`](https://github.com/astro-informatics/proxnest) - __Gaussian Benchmarking__ Interactive Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ProxNest.utils as utils\n",
    "import ProxNest.sampling as sampling\n",
    "import ProxNest.optimisations as optimisations\n",
    "import ProxNest.operators as operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate mock data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of Gaussian\n",
    "dimension = 200\n",
    "\n",
    "# A simple identity forward model and redundant dictionary\n",
    "phi = operators.sensing_operators.Identity()\n",
    "psi = operators.sensing_operators.Identity()\n",
    "\n",
    "# Generate a vector drawn from a Uniform distribution\n",
    "image = np.random.rand(dimension, 1)\n",
    "\n",
    "# Simulate some unit variance Gaussian noise on this random vector\n",
    "sigma = 1\n",
    "n = sigma*np.random.randn(dimension, 1)\n",
    "image = image + n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regularisation parameter (this should be tuned for a given problem)\n",
    "delta = 1/2\n",
    "\n",
    "# Parameter dictionary associated with optimisation problem of resampling from the prior subject to the likelihood iso-ball\n",
    "params = utils.create_parameters_dict(\n",
    "           y = image,                # Measurements i.e. data\n",
    "         Phi = phi,                  # Forward model\n",
    "     epsilon = 1e-3,                 # Radius of L2-ball of likelihood \n",
    "       tight = True,                 # Is Phi a tight frame or not?\n",
    "          nu = 1,                    # Bound on the squared-norm of Phi\n",
    "         tol = 1e-10,                # Convergence tolerance of algorithm\n",
    "    max_iter = 200,                  # Maximum number of iterations\n",
    "     verbose = 0,                    # Verbosity level\n",
    "           u = 0,                    # Initial vector for the dual problem\n",
    "         pos = True,                 # Positivity flag\n",
    "     reality = True                  # Reality flag\n",
    ")\n",
    "\n",
    "# Options dictionary associated with the overall sampling algorithm\n",
    "options = utils.create_options_dict(\n",
    "    samplesL = 2e4,                  # Number of live samples\n",
    "    samplesD = 3e5,                  # Number of discarded samples \n",
    "    thinning = 1e1,                  # Thinning factor (to mitigate correlations)\n",
    "       delta = 1e-2,                 # Discretisation stepsize\n",
    "        burn = 1e2,                  # Number of burn in samples\n",
    "       sigma = sigma                 # Noise standard deviation of degraded image\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda functions to evaluate cost function\n",
    "LogLikeliL = lambda sol : - np.linalg.norm(image-phi.dir_op(sol))**2/(2*sigma**2)\n",
    "\n",
    "# Lambda function for L2-norm identity prior backprojection steps\n",
    "proxH = lambda x, T : x - 2*T*psi.adj_op(psi.dir_op(x))*2*delta\n",
    "\n",
    "# Lambda function for L2-ball likelihood projection during resampling\n",
    "proxB = lambda x, tau: optimisations.l2_ball_proj.sopt_fast_proj_B2(x, tau, params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Proximal Nested Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProxNest || Initialise: 100%|██████████| 200/200 [00:00<00:00, 25110.33it/s]\n",
      "ProxNest || Populate: 100%|██████████| 200098/200098 [00:04<00:00, 44747.63it/s]\n",
      "ProxNest || Sample: 100%|██████████| 300000/300000 [00:24<00:00, 12010.62it/s]\n",
      "ProxNest || Compute Weights: 100%|██████████| 300000/300000 [00:00<00:00, 760985.59it/s]\n",
      "ProxNest || Trapezium Integrate: 100%|██████████| 299998/299998 [00:00<00:00, 1626459.59it/s]\n",
      "ProxNest || Estimate Variance: 100%|██████████| 300000/300000 [00:00<00:00, 362372.55it/s]\n",
      "ProxNest || Compute Posterior Mean: 100%|██████████| 300000/300000 [00:00<00:00, 394808.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Select a starting position\n",
    "X0 = np.abs(phi.adj_op(image))\n",
    "\n",
    "# Perform proximal nested sampling\n",
    "NS_BayEvi, NS_Trace = sampling.proximal_nested.ProxNestedSampling(X0, LogLikeliL, proxH, proxB, params, options)\n",
    "rescaled_evidence_estimate = NS_BayEvi[0] + np.log(np.pi/delta)*(dimension/2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate analytic evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detPar = 1/(2*delta+1/sigma**2)\n",
    "ySquare= np.linalg.norm(image,'fro')**2\n",
    "BayEvi_Val_gt_log = np.log(np.sqrt(((2*np.pi)**dimension)*(detPar**dimension))) + (-ySquare/(2*sigma**2)) + (detPar/2)*(ySquare/sigma**4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare evidence estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.39837084498416\n",
      "51.165404332833404\n"
     ]
    }
   ],
   "source": [
    "print(rescaled_evidence_estimate)\n",
    "print(BayEvi_Val_gt_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learned_nest_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
