{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# [`ProxNest`](https://github.com/astro-informatics/proxnest) - __Gaussian Benchmarking__ Interactive Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "import ProxNest as pxn\n",
    "import ProxNest.utils as utils\n",
    "import ProxNest.sampling as sampling\n",
    "import ProxNest.optimisations as optimisations\n",
    "import ProxNest.operators as operators\n",
    "\n",
    "import os\n",
    "# Set GPU ID\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate mock data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of Gaussian\n",
    "dimension = 200\n",
    "\n",
    "# A simple identity forward model and redundant dictionary\n",
    "phi = operators.sensing_operators.Identity()\n",
    "psi = operators.sensing_operators.Identity()\n",
    "\n",
    "# Generate a vector drawn from a Uniform distribution\n",
    "image = np.random.rand(dimension, 1)\n",
    "\n",
    "# Simulate some unit variance Gaussian noise on this random vector\n",
    "# sigma = 1\n",
    "# n = sigma*np.random.randn(dimension, 1)\n",
    "# image = image + n\n",
    "\n",
    "ISNR = 15\n",
    "sigma = np.sqrt(np.mean(np.abs(image)**2)) * 10**(-ISNR/20)\n",
    "n = np.random.normal(0, sigma, image.shape)\n",
    "image = image + n\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a regularisation parameter (this should be tuned for a given problem)\n",
    "# delta = 1/2\n",
    "\n",
    "# Parameter dictionary associated with optimisation problem of resampling from the prior subject to the likelihood iso-ball\n",
    "params = utils.create_parameters_dict(\n",
    "           y = image,                # Measurements i.e. data\n",
    "         Phi = phi,                  # Forward model\n",
    "     epsilon = 1e-3,                 # Radius of L2-ball of likelihood \n",
    "       tight = True,                 # Is Phi a tight frame or not?\n",
    "          nu = 1,                    # Bound on the squared-norm of Phi\n",
    "         tol = 1e-10,                # Convergence tolerance of algorithm\n",
    "    max_iter = 200,                  # Maximum number of iterations\n",
    "     verbose = 0,                    # Verbosity level\n",
    "           u = 0,                    # Initial vector for the dual problem\n",
    "         pos = True,                 # Positivity flag\n",
    "     reality = True                  # Reality flag\n",
    ")\n",
    "\n",
    "# Options dictionary associated with the overall sampling algorithm\n",
    "options = utils.create_options_dict(\n",
    "    samplesL = 2e4,                  # Number of live samples\n",
    "    samplesD = 3e5,                  # Number of discarded samples \n",
    "    thinning = 1e1,                  # Thinning factor (to mitigate correlations)\n",
    "       delta = 1e-2,                 # Discretisation stepsize\n",
    "        burn = 1e2,                  # Number of burn in samples\n",
    "       sigma = sigma,                # Noise standard deviation of degraded image\n",
    "       gamma = sigma**2,             # Gamma parameter of the prior term. Using noise variance\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda functions to evaluate cost function\n",
    "LogLikeliL = lambda sol : - np.linalg.norm(image-phi.dir_op(sol))**2/(2*sigma**2)\n",
    "\n",
    "# # Lambda function for L2-norm identity prior backprojection steps\n",
    "# proxH = lambda x, T : x - 2*T*psi.adj_op(psi.dir_op(x))*2*delta\n",
    "# Saved dir of the model in SavedModel format\n",
    "saved_model_path = '/disk/xray0/tl3/repos/lexci_models/DnCNN/snr_15_model.pb'\n",
    "# Load DnCNN denoiser prox\n",
    "proxH = pxn.operators.learned_operators.prox_DnCNN(saved_model_path)\n",
    "\n",
    "# Lambda function for L2-ball likelihood projection during resampling\n",
    "proxB = lambda x, tau: optimisations.l2_ball_proj.sopt_fast_proj_B2(x, tau, params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Proximal Nested Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ProxNest || Initialise:   0%|          | 0/200 [00:00<?, ?it/s]2023-06-16 11:43:14.630216: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2023-06-16 11:43:15.314626: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "ProxNest || Initialise: 100%|██████████| 200/200 [00:02<00:00, 78.91it/s] \n",
      "ProxNest || Populate:   7%|▋         | 13656/200098 [00:19<04:31, 687.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m X0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(phi\u001b[39m.\u001b[39madj_op(image))\n\u001b[1;32m      4\u001b[0m \u001b[39m# Perform proximal nested sampling\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m NS_BayEvi, NS_Trace \u001b[39m=\u001b[39m sampling\u001b[39m.\u001b[39;49mproximal_nested\u001b[39m.\u001b[39;49mProxNestedSampling(X0, LogLikeliL, proxH, proxB, params, options)\n\u001b[1;32m      6\u001b[0m rescaled_evidence_estimate \u001b[39m=\u001b[39m NS_BayEvi[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mlog(np\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39mdelta)\u001b[39m*\u001b[39m(dimension\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/disk/xray0/tl3/repos/proxnest/ProxNest/sampling/proximal_nested.py:96\u001b[0m, in \u001b[0;36mProxNestedSampling\u001b[0;34m(X0, LikeliL, proxH, proxB, params, options)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39m# Obtain samples from priors\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m ii \u001b[39min\u001b[39;00m tqdm(\n\u001b[1;32m     91\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, NumLiveSetSamples \u001b[39m*\u001b[39m options[\u001b[39m\"\u001b[39m\u001b[39mthinning\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m options[\u001b[39m\"\u001b[39m\u001b[39mburn\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m     92\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProxNest || Populate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m ):\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m     \u001b[39m# P-ULA -- MARKOV CHAIN generating live samples\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     Xcur \u001b[39m=\u001b[39m driftIniN(Xcur, delta, gamma) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39msqrt(delta) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\n\u001b[1;32m     97\u001b[0m         Xcur\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], Xcur\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m     \u001b[39m# Save sample (with thinning)\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m (ii \u001b[39m>\u001b[39m options[\u001b[39m\"\u001b[39m\u001b[39mburn\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    102\u001b[0m         (ii \u001b[39m-\u001b[39m options[\u001b[39m\"\u001b[39m\u001b[39mburn\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m%\u001b[39m options[\u001b[39m\"\u001b[39m\u001b[39mthinning\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    103\u001b[0m     ):\n\u001b[1;32m    104\u001b[0m         \u001b[39m# Record the current sample in the live set and its likelihood\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray0/tl3/repos/proxnest/ProxNest/sampling/proximal_nested.py:41\u001b[0m, in \u001b[0;36mProxNestedSampling.<locals>.<lambda>\u001b[0;34m(X, delta, gamma)\u001b[0m\n\u001b[1;32m     35\u001b[0m lg\u001b[39m.\u001b[39minfo_log(\u001b[39m\"\u001b[39m\u001b[39mConstructing lambda functions for resampling projections...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[39m# Simulation setup\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m# Use backward-forward splitting to approximate proxPi using proxH and gradF\u001b[39;00m\n\u001b[1;32m     39\u001b[0m driftIniN \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m X, delta, gamma: np\u001b[39m.\u001b[39mreal(\n\u001b[1;32m     40\u001b[0m     (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m delta \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m gamma)) \u001b[39m*\u001b[39m X \n\u001b[0;32m---> 41\u001b[0m     \u001b[39m+\u001b[39m delta \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m gamma) \u001b[39m*\u001b[39m proxH(X, gamma)\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m drift \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m X, delta, lamb, tau, gamma, sigma: np\u001b[39m.\u001b[39mreal(\n\u001b[1;32m     44\u001b[0m     (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m delta \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m lamb) \u001b[39m-\u001b[39m delta \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m gamma)) \u001b[39m*\u001b[39m X\n\u001b[1;32m     45\u001b[0m     \u001b[39m+\u001b[39m delta \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m gamma) \u001b[39m*\u001b[39m proxH(X, gamma)\n\u001b[1;32m     46\u001b[0m     \u001b[39m+\u001b[39m delta \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m lamb) \u001b[39m*\u001b[39m proxB(X, np\u001b[39m.\u001b[39msqrt(tau \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m sigma\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[39m# Initialize variables\u001b[39;00m\n",
      "File \u001b[0;32m/disk/xray0/tl3/repos/proxnest/ProxNest/operators/learned_operators.py:25\u001b[0m, in \u001b[0;36m_DnCNN_denoise\u001b[0;34m(noisy_img, sigma, tf_model)\u001b[0m\n\u001b[1;32m     23\u001b[0m tf_noisy_img \u001b[39m=\u001b[39m tf_noisy_img[tf\u001b[39m.\u001b[39mnewaxis,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,tf\u001b[39m.\u001b[39mnewaxis]\n\u001b[1;32m     24\u001b[0m \u001b[39m# Denoise\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m tf_denoised_img \u001b[39m=\u001b[39m tf_model(tf_noisy_img)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Remove extra dimensions and convert to numpy\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39msqueeze(tf_denoised_img, axis\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m])\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:701\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_attribute\u001b[39m(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 701\u001b[0m   \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:949\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    947\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 949\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    950\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    951\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    952\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/disk/xray0/tl3/miniconda3/envs/learned_nest_tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Select a starting position\n",
    "X0 = np.abs(phi.adj_op(image))\n",
    "\n",
    "# Perform proximal nested sampling\n",
    "NS_BayEvi, NS_Trace = sampling.proximal_nested.ProxNestedSampling(\n",
    "    X0, LogLikeliL, proxH, proxB, params, options\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1/2\n",
    "rescaled_evidence_estimate = NS_BayEvi[0] + np.log(np.pi/delta)*(dimension/2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate analytic evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detPar = 1/(2*delta+1/sigma**2)\n",
    "ySquare= np.linalg.norm(image,'fro')**2\n",
    "BayEvi_Val_gt_log = np.log(\n",
    "    np.sqrt(((2*np.pi)**dimension)*(detPar**dimension))\n",
    ") + (-ySquare/(2*sigma**2)) + (detPar/2)*(ySquare/sigma**4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare evidence estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.417582097813664\n",
      "48.57235865861398\n"
     ]
    }
   ],
   "source": [
    "print(rescaled_evidence_estimate)\n",
    "print(BayEvi_Val_gt_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learned_nest_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
